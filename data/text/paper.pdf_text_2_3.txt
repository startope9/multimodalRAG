(timestamps, UUIDs), and standardization of numeric values. 
Enrichment may incorporate geolocation lookups for IP 
addresses, user-agent parsing, or contextual metadata from 
upstream systems. The output of this stage is a cleaned, 
metadata-enriched log record, ready for downstream semantic 
processing. 
B.​ Summarization and Feature Extraction 
Semantic Summarization: For verbose or multi-line entries 
(e.g., stack traces), an optional summarization service uses a 
lightweight transformer fine-tuned on generic log corpora to 
condense messages into concise “event descriptions” [1]. This 
step reduces noise and focuses feature extraction on the core 
failure or informational content. 
N-gram 
and 
Syntactic 
Features: 
In 
parallel, 
traditional n-gram frequency vectors and part-of-speech (POS) 
tag distributions are computed to capture syntactic patterns. 
These 
features 
complement 
semantic embeddings by 
preserving structural cues useful for certain classification tasks 
(e.g., distinguishing configuration errors from execution 
errors). 
Metadata Feature Encoding: Categorical metadata 
(severity, 
host, 
application 
module) 
are 
one-hot 
or 
embedding-encoded, 
enabling 
the 
model 
to 
leverage 
operational context in labeling tasks beyond pure semantics 
(e.g., differentiating a “timeout” error on a web server vs. 
database server). 
C.​ Embedding Generation 
Pretrained Embedding Models: Normalized and summarized